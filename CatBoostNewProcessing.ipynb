{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c91ffd4d-6c90-4eba-b554-0dd05bc379fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "import datetime\n",
    "import pandas as pd\n",
    "from catboost import Pool\n",
    "from collections import Counter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e813407b-b1f8-4912-b417-4bcd3b84c19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "df = pd.read_csv(\"../../data/processed/train_preprocess_v1.csv\")\n",
    "df.shape\n",
    "\n",
    "# Creamos un df_train sobre el que hacer las transformaciones\n",
    "train_df = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5310fcd2-0f66-44f0-9f29-71aea373430e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_info_without_stopwords</th>\n",
       "      <th>pos_freq_without_stopwords</th>\n",
       "      <th>lemma_freq_without_stopwords</th>\n",
       "      <th>tag_freq_without_stopwords</th>\n",
       "      <th>processed_subject</th>\n",
       "      <th>speaker_entities</th>\n",
       "      <th>speaker_type</th>\n",
       "      <th>speaker_job_tokens</th>\n",
       "      <th>state_info_tokens</th>\n",
       "      <th>party_affiliation_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new_york</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'china', 'pos': 'PROPN', 'tag': 'NN...</td>\n",
       "      <td>Counter({'PROPN': 4, 'NOUN': 4, 'ADJ': 1, 'VER...</td>\n",
       "      <td>Counter({'china': 2, 'south': 1, 'sea': 1, 'bu...</td>\n",
       "      <td>Counter({'NNP': 4, 'NN': 3, 'JJ': 1, 'NNS': 1,...</td>\n",
       "      <td>['china', 'foreign-policy', 'military']</td>\n",
       "      <td>['donald trump']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['president', '-', 'elect']</td>\n",
       "      <td>['new_york']</td>\n",
       "      <td>['republican']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>with the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>u.s. senator</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>[{'lemma': 'resource', 'pos': 'NOUN', 'tag': '...</td>\n",
       "      <td>Counter({'NOUN': 7, 'VERB': 4, 'PROPN': 2, 'AD...</td>\n",
       "      <td>Counter({'resource': 1, 'take': 1, 'execute': ...</td>\n",
       "      <td>Counter({'NN': 4, 'NNS': 3, 'VB': 2, 'NNP': 2,...</td>\n",
       "      <td>['health-care']</td>\n",
       "      <td>['chris dodd']</td>\n",
       "      <td>['PERSON']</td>\n",
       "      <td>['u.s', '.', 'senator']</td>\n",
       "      <td>['connecticut']</td>\n",
       "      <td>['democrat']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  china is in the south china sea and (building)...   \n",
       "1  30c2723a188      0  with the resources it takes to execute just ov...   \n",
       "\n",
       "                         subject       speaker      speaker_job   state_info  \\\n",
       "0  china,foreign-policy,military  donald-trump  president-elect     new_york   \n",
       "1                    health-care    chris-dodd     u.s. senator  connecticut   \n",
       "\n",
       "  party_affiliation party_affiliation_uni party_affiliation_category_map  ...  \\\n",
       "0        republican            republican          political-affiliation  ...   \n",
       "1          democrat              democrat          political-affiliation  ...   \n",
       "\n",
       "                          pos_info_without_stopwords  \\\n",
       "0  [{'lemma': 'china', 'pos': 'PROPN', 'tag': 'NN...   \n",
       "1  [{'lemma': 'resource', 'pos': 'NOUN', 'tag': '...   \n",
       "\n",
       "                          pos_freq_without_stopwords  \\\n",
       "0  Counter({'PROPN': 4, 'NOUN': 4, 'ADJ': 1, 'VER...   \n",
       "1  Counter({'NOUN': 7, 'VERB': 4, 'PROPN': 2, 'AD...   \n",
       "\n",
       "                        lemma_freq_without_stopwords  \\\n",
       "0  Counter({'china': 2, 'south': 1, 'sea': 1, 'bu...   \n",
       "1  Counter({'resource': 1, 'take': 1, 'execute': ...   \n",
       "\n",
       "                          tag_freq_without_stopwords  \\\n",
       "0  Counter({'NNP': 4, 'NN': 3, 'JJ': 1, 'NNS': 1,...   \n",
       "1  Counter({'NN': 4, 'NNS': 3, 'VB': 2, 'NNP': 2,...   \n",
       "\n",
       "                         processed_subject  speaker_entities speaker_type  \\\n",
       "0  ['china', 'foreign-policy', 'military']  ['donald trump']   ['PERSON']   \n",
       "1                          ['health-care']    ['chris dodd']   ['PERSON']   \n",
       "\n",
       "            speaker_job_tokens state_info_tokens party_affiliation_tokens  \n",
       "0  ['president', '-', 'elect']      ['new_york']           ['republican']  \n",
       "1      ['u.s', '.', 'senator']   ['connecticut']             ['democrat']  \n",
       "\n",
       "[2 rows x 31 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f379627f-a027-4786-9520-f40f829664e2",
   "metadata": {},
   "source": [
    "## Selección de categorías\n",
    "\n",
    "A continuación se describen brevemente las características útiles para el modelo:\n",
    "\n",
    "### id\n",
    "\n",
    "La variable `id` carece de poder descriptivo. Se añade a las columnas a eliminar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e0ddc99f-e097-4ae8-9ff7-76f15f4fc6d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"id\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27c1f4c-f668-43aa-8b57-d6220173f98f",
   "metadata": {},
   "source": [
    "### Statement \n",
    "\n",
    "La variable `statement` resulta muy útil para el modelo. En este caso, se declarará como variable de tipo texto para que CatBoost la identifique como tal y le aplique el procesamiento nativo adecuado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ced7323d-a8ec-4f23-a548-ec8c485272e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_features = [\"statement\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "288716ea-0696-4591-9256-e2bf9ab16382",
   "metadata": {},
   "source": [
    "### Variables derivadas del procesado de Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dba3b4d-e82b-46d5-b5b8-2b78dbbfb4c4",
   "metadata": {},
   "source": [
    "En relación con `statement`, tenemos `statement_tokens`, que no es procesable nativamente para CatBoost. Como ya se va a representar el efecto del statement con la variable original, se elimina del modelo. Su variante sin stopwords, también se quita, y la lista de stopwords también."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7e93ac90-c389-434a-8aaa-4bbc658633ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id', 'statement_tokens', 'statement_tokens_without_stopwords', 'stopwords']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"statement_tokens\", \"statement_tokens_without_stopwords\", \"stopwords\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c95f83f-247c-440b-9c24-5b379552323d",
   "metadata": {},
   "source": [
    "Se podría evaluar su rendimiento en sustitución de `statement` procesada por CatBoost. Se verá más adelante. Gracias al procesamiento nativo de CatBoost de variables de tipo texto, obtiene de forma natural estadísticas derivadas de la tokenización, por lo que eliminaremos estas variables y nos quedaremos con las que tienen significado en términos de análisis linguístico. \n",
    "\n",
    "También están los contadores de tokens, que se dejarán en una primera iteración, pero teniendo presente el procesamiento nativo de CatBoost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a8f6c1d4-b72f-4623-b6c3-f493aada080e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"num_stopwords_tokens\"] = train_df[\"num_tokens\"] - train_df[\"num_tokens_without_stopwords\"]\n",
    "drop_cols += [\"num_tokens_without_stopwords\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58a0e0c2-64da-4966-a8f4-4f30136946b6",
   "metadata": {},
   "source": [
    "Se observa `num_sentences` porque a pesar de que CatBoost procesa tokens, no sabemos si obtiene información sobre el número de frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43a7ace-5d53-4912-a2bc-23a83b3bb4d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    8950.000000\n",
       "mean        1.136983\n",
       "std         0.469908\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         1.000000\n",
       "75%         1.000000\n",
       "max        14.000000\n",
       "Name: num_sentences, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"num_sentences\"].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ef7371e-2e29-464e-87de-9be7ec044483",
   "metadata": {},
   "source": [
    "Debido a que incluso por debajo del percentil 75, la mayoría de los valores es 1, se decide eliminarla del modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01832c80-cbf2-4261-87ba-ba5e18578106",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"num_sentences\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674db195-386e-4fb7-a794-84d52a79a5fb",
   "metadata": {},
   "source": [
    "#### POS\n",
    "\n",
    "Tenemos `pos_info` y `pos_freq`, con sus variantes `without_stopwords`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "220253dd-5a83-4595-a0df-d3bbb51441d8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [{'lemma': 'china', 'pos': 'PROPN', 'tag': 'NN...\n",
       "1    [{'lemma': 'with', 'pos': 'ADP', 'tag': 'IN', ...\n",
       "Name: pos_info, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pos_info\"].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fe307741-e59b-43f8-8100-b44a5b77c381",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Counter({'PROPN': 4, 'NOUN': 4, 'DET': 3, 'AUX...\n",
       "1    Counter({'NOUN': 7, 'ADP': 5, 'VERB': 4, 'DET'...\n",
       "Name: pos_freq, dtype: object"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"pos_freq\"].head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de01686-e196-49c9-b213-21219269f8b6",
   "metadata": {},
   "source": [
    "`pos_info`contiene la clasificación de palabras del statement, y `pos_freq`el número de palabras de cada tipo. Se va a tratar de representar el estilo de lenguaje a través de métricas obtenidas de estas variables: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ae12c17-2a2d-4abc-95ef-cee8f5f9f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "from collections import Counter\n",
    "\n",
    "# Convertir a diccionario limpio\n",
    "def clean_counter(x):\n",
    "    if isinstance(x, str) and x.startswith(\"Counter(\"):\n",
    "        try:\n",
    "            return ast.literal_eval(x.replace(\"Counter(\", \"\").rstrip(\")\"))\n",
    "        except:\n",
    "            return {}\n",
    "    elif isinstance(x, Counter):\n",
    "        return dict(x)\n",
    "    elif isinstance(x, dict):\n",
    "        return x\n",
    "    else:\n",
    "        return {}\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f76e9c15-6fa6-4967-8152-a50452490805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 32)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_count_PROPN</th>\n",
       "      <th>pos_count_NOUN</th>\n",
       "      <th>pos_count_DET</th>\n",
       "      <th>pos_count_AUX</th>\n",
       "      <th>pos_count_ADP</th>\n",
       "      <th>pos_count_PUNCT</th>\n",
       "      <th>pos_count_CCONJ</th>\n",
       "      <th>pos_count_ADJ</th>\n",
       "      <th>pos_count_PRON</th>\n",
       "      <th>pos_count_ADV</th>\n",
       "      <th>pos_count_PART</th>\n",
       "      <th>pos_count_VERB</th>\n",
       "      <th>pos_count_NUM</th>\n",
       "      <th>pos_count_SCONJ</th>\n",
       "      <th>pos_count_SYM</th>\n",
       "      <th>pos_count_X</th>\n",
       "      <th>pos_count_INTJ</th>\n",
       "      <th>pos_count_SPACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos_count_PROPN  pos_count_NOUN  pos_count_DET  pos_count_AUX  \\\n",
       "0                4               4              3              2   \n",
       "1                2               7              3              1   \n",
       "2                1               4              1              1   \n",
       "3                0              10              3              2   \n",
       "4                0               7              0              1   \n",
       "\n",
       "   pos_count_ADP  pos_count_PUNCT  pos_count_CCONJ  pos_count_ADJ  \\\n",
       "0              2                2                1              1   \n",
       "1              5                2                0              1   \n",
       "2              1                3                0              0   \n",
       "3              3                1                0              1   \n",
       "4              4                4                0              3   \n",
       "\n",
       "   pos_count_PRON  pos_count_ADV  pos_count_PART  pos_count_VERB  \\\n",
       "0               1              1               1               1   \n",
       "1               3              2               1               4   \n",
       "2               0              0               0               1   \n",
       "3               5              1               0               2   \n",
       "4               0              0               1               4   \n",
       "\n",
       "   pos_count_NUM  pos_count_SCONJ  pos_count_SYM  pos_count_X  pos_count_INTJ  \\\n",
       "0              0                0              0            0               0   \n",
       "1              1                0              0            0               0   \n",
       "2              0                0              0            0               0   \n",
       "3              0                0              0            0               0   \n",
       "4              0                0              0            0               0   \n",
       "\n",
       "   pos_count_SPACE  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                0  \n",
       "4                0  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "# Aplicar la conversión\n",
    "train_df[\"pos_freq_clean\"] = train_df[\"pos_freq\"].apply(clean_counter)\n",
    "train_df[\"pos_freq_without_stopwords_clean\"] = train_df[\"pos_freq_without_stopwords\"].apply(clean_counter)\n",
    "\n",
    "# Expandir en columnas\n",
    "pos_df = train_df[\"pos_freq_clean\"].apply(pd.Series).fillna(0).astype(int)\n",
    "pos_df_wo_stopwords = train_df[\"pos_freq_without_stopwords_clean\"].apply(pd.Series).fillna(0).astype(int)\n",
    "\n",
    "# Renombrar columnas\n",
    "pos_df.columns = [f\"pos_count_{col.upper()}\" for col in pos_df.columns]\n",
    "pos_df_wo_stopwords.columns = [f\"pos_{col.upper()}\" for col in pos_df_wo_stopwords.columns]\n",
    "\n",
    "pos_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0f3c5a09-2421-435d-9fa3-e950d3719bff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_PROPN</th>\n",
       "      <th>pos_NOUN</th>\n",
       "      <th>pos_ADJ</th>\n",
       "      <th>pos_VERB</th>\n",
       "      <th>pos_ADV</th>\n",
       "      <th>pos_NUM</th>\n",
       "      <th>pos_AUX</th>\n",
       "      <th>pos_SCONJ</th>\n",
       "      <th>pos_SYM</th>\n",
       "      <th>pos_PART</th>\n",
       "      <th>pos_PRON</th>\n",
       "      <th>pos_X</th>\n",
       "      <th>pos_ADP</th>\n",
       "      <th>pos_INTJ</th>\n",
       "      <th>pos_DET</th>\n",
       "      <th>pos_CCONJ</th>\n",
       "      <th>pos_PUNCT</th>\n",
       "      <th>pos_SPACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos_PROPN  pos_NOUN  pos_ADJ  pos_VERB  pos_ADV  pos_NUM  pos_AUX  \\\n",
       "0          4         4        1         1        0        0        0   \n",
       "1          2         7        1         4        1        0        0   \n",
       "2          1         4        0         1        0        0        0   \n",
       "3          0         9        1         1        0        0        0   \n",
       "4          0         7        3         4        0        0        0   \n",
       "\n",
       "   pos_SCONJ  pos_SYM  pos_PART  pos_PRON  pos_X  pos_ADP  pos_INTJ  pos_DET  \\\n",
       "0          0        0         0         0      0        0         0        0   \n",
       "1          0        0         0         0      0        0         0        0   \n",
       "2          0        0         0         0      0        0         0        0   \n",
       "3          0        0         0         0      0        0         0        0   \n",
       "4          0        0         0         0      0        0         0        0   \n",
       "\n",
       "   pos_CCONJ  pos_PUNCT  pos_SPACE  \n",
       "0          0          0          0  \n",
       "1          0          0          0  \n",
       "2          0          0          0  \n",
       "3          0          0          0  \n",
       "4          0          0          0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df_wo_stopwords.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b9dd95-2265-4de4-850b-b1af75fe7a22",
   "metadata": {},
   "source": [
    "Puesto que contienen información muy similar y la cantidad de stopwords se puede obtener a través de stopwords, se decide mantener únicamente una de ellas, la versión sin `stopwords`, por considerar que introducen menor ruido al modelo. Comprobamos los resultados de la transformación, verificando: \n",
    "- Número de columnas anteriores y actuales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "97ade692-46a5-49ab-9d3f-1bd5e39a73ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 34)\n",
      "(8950, 18)\n"
     ]
    }
   ],
   "source": [
    "# Comprobamos los resultados\n",
    "print(train_df.shape)\n",
    "print(pos_df_wo_stopwords.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae969ebf-8e11-4a87-8cbb-229b3e8b2044",
   "metadata": {},
   "source": [
    "Antes de nada, quitamos las versiones clean creadas anteriormente, para que el dataset vuelva a tener 31 columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "541c070e-5a68-4382-84e7-6892b1b8b96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "aux_drop_cols = [\"pos_freq_clean\", \"pos_freq_without_stopwords_clean\"]\n",
    "train_df = train_df.drop(columns=aux_drop_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3db2643c-caee-433f-ade6-65e800a9e26d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 50)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>...</th>\n",
       "      <th>pos_SYM</th>\n",
       "      <th>pos_PART</th>\n",
       "      <th>pos_PRON</th>\n",
       "      <th>pos_X</th>\n",
       "      <th>pos_ADP</th>\n",
       "      <th>pos_INTJ</th>\n",
       "      <th>pos_DET</th>\n",
       "      <th>pos_CCONJ</th>\n",
       "      <th>pos_PUNCT</th>\n",
       "      <th>pos_SPACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new_york</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  china is in the south china sea and (building)...   \n",
       "\n",
       "                         subject       speaker      speaker_job state_info  \\\n",
       "0  china,foreign-policy,military  donald-trump  president-elect   new_york   \n",
       "\n",
       "  party_affiliation party_affiliation_uni party_affiliation_category_map  ...  \\\n",
       "0        republican            republican          political-affiliation  ...   \n",
       "\n",
       "  pos_SYM  pos_PART  pos_PRON pos_X pos_ADP pos_INTJ pos_DET pos_CCONJ  \\\n",
       "0       0         0         0     0       0        0       0         0   \n",
       "\n",
       "  pos_PUNCT pos_SPACE  \n",
       "0         0         0  \n",
       "\n",
       "[1 rows x 50 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df, pos_df_wo_stopwords], axis=1)\n",
    "print(train_df.shape)\n",
    "train_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133760b9-f880-4144-8541-569b29c4a323",
   "metadata": {},
   "source": [
    "- Resultados: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ac9a710e-b96a-433e-9b83-693d9917827d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'NOUN': 7, 'VERB': 4, 'PROPN': 2, 'ADV': 1, 'ADJ': 1})\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pos_PROPN</th>\n",
       "      <th>pos_NOUN</th>\n",
       "      <th>pos_ADJ</th>\n",
       "      <th>pos_VERB</th>\n",
       "      <th>pos_ADV</th>\n",
       "      <th>pos_NUM</th>\n",
       "      <th>pos_AUX</th>\n",
       "      <th>pos_SCONJ</th>\n",
       "      <th>pos_SYM</th>\n",
       "      <th>pos_PART</th>\n",
       "      <th>pos_PRON</th>\n",
       "      <th>pos_X</th>\n",
       "      <th>pos_ADP</th>\n",
       "      <th>pos_INTJ</th>\n",
       "      <th>pos_DET</th>\n",
       "      <th>pos_CCONJ</th>\n",
       "      <th>pos_PUNCT</th>\n",
       "      <th>pos_SPACE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pos_PROPN  pos_NOUN  pos_ADJ  pos_VERB  pos_ADV  pos_NUM  pos_AUX  \\\n",
       "0          4         4        1         1        0        0        0   \n",
       "1          2         7        1         4        1        0        0   \n",
       "\n",
       "   pos_SCONJ  pos_SYM  pos_PART  pos_PRON  pos_X  pos_ADP  pos_INTJ  pos_DET  \\\n",
       "0          0        0         0         0      0        0         0        0   \n",
       "1          0        0         0         0      0        0         0        0   \n",
       "\n",
       "   pos_CCONJ  pos_PUNCT  pos_SPACE  \n",
       "0          0          0          0  \n",
       "1          0          0          0  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(df[\"pos_freq_without_stopwords\"].iloc[1])\n",
    "pos_df_wo_stopwords.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69269853-4965-4628-ad7f-d3c3599ab975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pos_PROPN    15079\n",
       "pos_NOUN     41363\n",
       "pos_ADJ       9244\n",
       "pos_VERB     18197\n",
       "pos_ADV       1912\n",
       "pos_NUM       2244\n",
       "pos_AUX        361\n",
       "pos_SCONJ       36\n",
       "pos_SYM       1117\n",
       "pos_PART       463\n",
       "pos_PRON        66\n",
       "pos_X           45\n",
       "pos_ADP        294\n",
       "pos_INTJ        32\n",
       "pos_DET         57\n",
       "pos_CCONJ       16\n",
       "pos_PUNCT        7\n",
       "pos_SPACE      291\n",
       "dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pos_df_wo_stopwords.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab88982-500e-4f55-8149-db6040e5f52a",
   "metadata": {},
   "source": [
    "Se observa su frecuencia por si fuera interesante reducir cardinalidad."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b98b656-3f37-4da5-8702-453a05b97d11",
   "metadata": {},
   "source": [
    "Eliminamos las columnas de POS:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3e7a694b-03a5-44a9-8b83-2f4ad6b1fc7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"pos_info\", \"pos_freq\", \"pos_freq_without_stopwords\",\"pos_info_without_stopwords\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "467fb9a0-342e-48d7-99be-3cc2f65f2274",
   "metadata": {},
   "source": [
    "#### Lemma y Tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "db23f677-bef3-4f8d-97ea-f18ad27aacbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a ambas columnas\n",
    "train_df[\"lemma_freq_clean\"] = df[\"lemma_freq\"].apply(clean_counter)\n",
    "train_df[\"tag_freq_clean\"] = df[\"tag_freq\"].apply(clean_counter)\n",
    "\n",
    "# Expandir lemas\n",
    "lemma_df = train_df[\"lemma_freq_clean\"].apply(pd.Series).fillna(0).astype(int)\n",
    "lemma_df.columns = [f\"lemma_count_{col}\" for col in lemma_df.columns]\n",
    "\n",
    "# Expandir tags\n",
    "tag_df = train_df[\"tag_freq_clean\"].apply(pd.Series).fillna(0).astype(int)\n",
    "tag_df.columns = [f\"tag_count_{col}\" for col in tag_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "541ac6f2-a7f6-45ef-b7ff-d1b3ab942316",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_aux_cols = [\"lemma_freq_clean\",\"tag_freq_clean\"]\n",
    "train_df = train_df.drop(columns=drop_aux_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17a0d41b-0789-46b7-a637-d0e1aa0decdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 50)\n",
      "(8950, 9357)\n",
      "(8950, 50)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(lemma_df.shape)\n",
    "print(tag_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67826ce9-c3c0-48ef-b8d4-082390103ab4",
   "metadata": {},
   "source": [
    "`lemma_freq` incluye palabras que carecen de importancia para el modelo, por lo que, debido a su cardinalidad, finalmente no se incluye. Se elimina del dataset. \n",
    "\n",
    "Por otro lado, `tag` incluye una clasificación de tipología de palabras más específica que POS. Se evalúa sin stopwords por si reduce significativamente la cardinalidad y resulta relevante para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b1a04605-b472-4b17-9fec-d1a148e737cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"lemma_freq\",\"tag_freq\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6f960bb-288e-4d0e-8bbc-c4fb60e45fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 50)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "497f932b-6586-45bb-aa3d-39c5b214ce19",
   "metadata": {},
   "source": [
    "Dado que en lemma se incluyen `stopwords`, se observa la diferencia entre ambas para ver si lemma_freq_without_stopwords aportaría información"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "89ee1227-9df8-4d21-886a-21204462a5b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Counter({'the': 3, 'china': 2, 'be': 1, 'in': ...\n",
       "1       Counter({'the': 3, 'of': 2, 'with': 1, 'resour...\n",
       "2       Counter({'the': 1, '(': 1, 'wisconsin': 1, ')'...\n",
       "3       Counter({'be': 2, 'a': 2, 'say': 1, 'her': 1, ...\n",
       "4       Counter({'at': 1, 'protest': 1, 'in': 1, 'wisc...\n",
       "                              ...                        \n",
       "8945    Counter({'do': 2, 'the': 2, 'if': 1, 'rhode': ...\n",
       "8946    Counter({'health': 2, 'care': 2, 'the': 1, 'ne...\n",
       "8947    Counter({'the': 2, 'health': 1, 'insurance': 1...\n",
       "8948    Counter({'a': 3, '.': 2, 'no': 1, 'one': 1, 'i...\n",
       "8949    Counter({'say': 1, 'the': 1, 'army': 1, 'be': ...\n",
       "Name: lemma_freq, Length: 8950, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemma_freq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6eb38d0a-4ae6-4526-b967-b05e756794f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Counter({'china': 2, 'south': 1, 'sea': 1, 'bu...\n",
       "1       Counter({'resource': 1, 'take': 1, 'execute': ...\n",
       "2       Counter({'wisconsin': 1, 'governor': 1, 'propo...\n",
       "3       Counter({'say': 1, 'representation': 1, 'ex': ...\n",
       "4       Counter({'protest': 1, 'wisconsin': 1, 'propos...\n",
       "                              ...                        \n",
       "8945    Counter({'rhode': 1, 'island': 1, 'hybrid': 1,...\n",
       "8946    Counter({'health': 2, 'care': 2, 'new': 1, 'la...\n",
       "8947    Counter({'health': 1, 'insurance': 1, 'plan': ...\n",
       "8948    Counter({'american': 1, 'history': 1, 'move': ...\n",
       "8949    Counter({'say': 1, 'army': 1, 'spend': 1, '$':...\n",
       "Name: lemma_freq_without_stopwords, Length: 8950, dtype: object"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"lemma_freq_without_stopwords\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb63dcaf-6094-4642-a273-7827d5c79017",
   "metadata": {},
   "source": [
    "Puede ser interesante, dependiendo de cuánto se reduzca la cardinalidad. Evaluamos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2c062fa5-86b9-4187-863f-fe2f359c242e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a ambas columnas\n",
    "#train_df[\"lemma_freq_without_stopwords\"] = df[\"lemma_freq_without_stopwords\"].apply(clean_counter)\n",
    "train_df[\"tag_freq_without_stopwords\"] = df[\"tag_freq_without_stopwords\"].apply(clean_counter)\n",
    "\n",
    "# Expandir lemas\n",
    "#lemma_df = train_df[\"lemma_freq_without_stopwords\"].apply(pd.Series).fillna(0).astype(int)\n",
    "#lemma_df.columns = [f\"lemma_count_{col}\" for col in lemma_df.columns]\n",
    "\n",
    "# Expandir tags\n",
    "tag_df = train_df[\"tag_freq_without_stopwords\"].apply(pd.Series).fillna(0).astype(int)\n",
    "tag_df.columns = [f\"tag_count_{col}\" for col in tag_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fa2d7151-b96a-4f4e-99ad-771b4cafe82e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8950, 50)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5f6fa7b0-b814-46a5-8e53-d34bf112dcca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tag_count_NNP     14526\n",
       "tag_count_NN      29119\n",
       "tag_count_JJ       8380\n",
       "tag_count_NNS     12294\n",
       "tag_count_VBN      3625\n",
       "tag_count_VB       3465\n",
       "tag_count_VBZ      3798\n",
       "tag_count_RB       2297\n",
       "tag_count_VBD      3667\n",
       "tag_count_VBG      2685\n",
       "tag_count_JJS       507\n",
       "tag_count_CD       2244\n",
       "tag_count_VBP      1272\n",
       "tag_count_MD         43\n",
       "tag_count_IN        318\n",
       "tag_count_JJR       356\n",
       "tag_count_$        1116\n",
       "tag_count_RBS        27\n",
       "tag_count_NNPS      555\n",
       "tag_count_FW         21\n",
       "tag_count_UH         32\n",
       "tag_count_ADD         7\n",
       "tag_count_RBR        50\n",
       "tag_count_PDT        51\n",
       "tag_count_RP         12\n",
       "tag_count_DT         11\n",
       "tag_count_LS          7\n",
       "tag_count_XX         10\n",
       "tag_count_CC         16\n",
       "tag_count_WDT         2\n",
       "tag_count_SYM         1\n",
       "tag_count_,           2\n",
       "tag_count_PRP$        2\n",
       "tag_count_:           2\n",
       "tag_count__SP       291\n",
       "tag_count_``          2\n",
       "tag_count_TO          1\n",
       "tag_count_PRP         8\n",
       "tag_count_AFX         1\n",
       "tag_count_NFP         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tag_df.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63061e7c-4c0b-4804-b6ea-9fc99e9e157b",
   "metadata": {},
   "source": [
    "Se reduce, pero no suficiente. No se añade. En el caso de `tag_freq_without_stopwords`, se evalua filtrar por frecuencia o por media. Tras hacer el estudio por media, se ve que no es interesante por lo que finalmente se filtra por frecuencia. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e2cca433-2365-4510-83fd-360a8ac20ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_cols = [col for col in tag_df.columns if col.startswith(\"tag_count_\")]\n",
    "\n",
    "# Frecuencia total\n",
    "tag_counts = tag_df[tag_cols].sum().sort_values(ascending=False)\n",
    "\n",
    "# Umbral\n",
    "threshold = 1000\n",
    "tag_to_keep = tag_counts[tag_counts >= threshold].index.tolist()\n",
    "tag_to_drop = tag_counts[tag_counts < threshold].index.tolist()\n",
    "\n",
    "# Columna para los que no superan el umbral\n",
    "tag_df[\"tag_OTHER\"] = tag_df[tag_to_drop].any(axis=1).astype(int)\n",
    "\n",
    "# Eliminar los tags raros\n",
    "tag_df = tag_df.drop(columns=tag_to_drop, errors=\"ignore\")\n",
    "train_df = pd.concat([train_df, tag_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1715e22e-9fd0-4f3a-94f8-36136b2773c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8950, 14)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(8950, 64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(tag_df.shape)\n",
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "35fd0873-831d-4596-a464-7eb3bb898c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>...</th>\n",
       "      <th>tag_count_VBN</th>\n",
       "      <th>tag_count_VB</th>\n",
       "      <th>tag_count_VBZ</th>\n",
       "      <th>tag_count_RB</th>\n",
       "      <th>tag_count_VBD</th>\n",
       "      <th>tag_count_VBG</th>\n",
       "      <th>tag_count_CD</th>\n",
       "      <th>tag_count_VBP</th>\n",
       "      <th>tag_count_$</th>\n",
       "      <th>tag_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new_york</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>with the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>u.s. senator</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  china is in the south china sea and (building)...   \n",
       "1  30c2723a188      0  with the resources it takes to execute just ov...   \n",
       "\n",
       "                         subject       speaker      speaker_job   state_info  \\\n",
       "0  china,foreign-policy,military  donald-trump  president-elect     new_york   \n",
       "1                    health-care    chris-dodd     u.s. senator  connecticut   \n",
       "\n",
       "  party_affiliation party_affiliation_uni party_affiliation_category_map  ...  \\\n",
       "0        republican            republican          political-affiliation  ...   \n",
       "1          democrat              democrat          political-affiliation  ...   \n",
       "\n",
       "  tag_count_VBN  tag_count_VB  tag_count_VBZ tag_count_RB tag_count_VBD  \\\n",
       "0             1             0              0            0             0   \n",
       "1             0             2              1            1             1   \n",
       "\n",
       "  tag_count_VBG tag_count_CD tag_count_VBP tag_count_$ tag_OTHER  \n",
       "0             0            0             0           0         0  \n",
       "1             0            0             0           0         0  \n",
       "\n",
       "[2 rows x 64 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4aaa98db-156e-43cd-8ef1-42ef6cc6ca99",
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols += [\"lemma_freq_without_stopwords\",\"tag_freq_without_stopwords\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc85973-035c-451b-b703-a6f995b6f487",
   "metadata": {},
   "source": [
    "### Subject\n",
    "\n",
    "Para reflejar el efecto de subject, vamos a utilizar encoding sobre `processed_subject`, su versión tokenizada. Por tanto, descartamos `subject` y obtendremos dummies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "15a8d51d-c171-4c81-84bd-b76094585a08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"subject\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "67dd176c-b21a-4b64-9204-4269bc109ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "# Convertir strings tipo \"[tax, healthcare]\" en listas reales\n",
    "train_df[\"processed_subject\"] = df[\"processed_subject\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "# Aplanar la lista de subjects\n",
    "all_subjects = [item for sublist in train_df[\"processed_subject\"] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "64dd462a-a285-43ce-ba1f-9137c327f6e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['economy',\n",
       " 'health-care',\n",
       " 'taxes',\n",
       " 'federal-budget',\n",
       " 'education',\n",
       " 'jobs',\n",
       " 'state-budget',\n",
       " 'candidates-biography',\n",
       " 'elections',\n",
       " 'immigration',\n",
       " 'foreign-policy',\n",
       " 'crime',\n",
       " 'history',\n",
       " 'energy',\n",
       " 'legal-issues',\n",
       " 'environment',\n",
       " 'guns',\n",
       " 'military',\n",
       " 'job-accomplishments',\n",
       " 'workers',\n",
       " 'terrorism',\n",
       " 'abortion',\n",
       " 'message-machine-2012',\n",
       " 'transportation',\n",
       " 'criminal-justice',\n",
       " 'state-finances',\n",
       " 'states',\n",
       " 'public-health',\n",
       " 'deficit',\n",
       " 'pundits',\n",
       " 'congress',\n",
       " 'women',\n",
       " 'message-machine',\n",
       " 'corrections-and-updates',\n",
       " 'children',\n",
       " 'campaign-finance',\n",
       " 'voting-record',\n",
       " 'medicare',\n",
       " 'stimulus',\n",
       " 'labor',\n",
       " 'income',\n",
       " 'poverty',\n",
       " 'government-regulation',\n",
       " 'ethics',\n",
       " 'religion',\n",
       " 'public-safety',\n",
       " 'polls',\n",
       " 'government-efficiency',\n",
       " 'corporations',\n",
       " 'iraq',\n",
       " 'social-security',\n",
       " 'climate-change',\n",
       " 'market-regulation',\n",
       " 'city-government',\n",
       " 'debt',\n",
       " 'families',\n",
       " 'homeland-security',\n",
       " 'gays-and-lesbians',\n",
       " 'financial-regulation',\n",
       " 'civil-rights',\n",
       " 'abc-news-week',\n",
       " 'drugs',\n",
       " 'trade',\n",
       " 'bipartisanship',\n",
       " 'housing',\n",
       " 'medicaid',\n",
       " 'diversity',\n",
       " 'supreme-court',\n",
       " 'retirement',\n",
       " 'campaign-advertising',\n",
       " 'unions',\n",
       " 'small-business',\n",
       " 'sports',\n",
       " 'science',\n",
       " 'city-budget',\n",
       " 'agriculture',\n",
       " 'human-rights',\n",
       " 'transparency',\n",
       " 'debates',\n",
       " 'county-budget',\n",
       " 'veterans',\n",
       " 'nuclear',\n",
       " 'technology',\n",
       " 'congressional-rules',\n",
       " 'county-government',\n",
       " 'new-hampshire-2012',\n",
       " 'marriage',\n",
       " 'marijuana',\n",
       " 'welfare',\n",
       " 'infrastructure',\n",
       " 'oil-spill',\n",
       " 'afghanistan',\n",
       " 'wealth',\n",
       " 'china',\n",
       " 'florida',\n",
       " 'sexuality',\n",
       " 'water',\n",
       " 'population',\n",
       " 'animals',\n",
       " 'pensions']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Seleccionar los más comunes\n",
    "subject_counts = Counter(all_subjects)\n",
    "top_n = 100\n",
    "top_subjects = [s for s, count in subject_counts.most_common(top_n)]\n",
    "top_subjects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3920cc7-30ab-4bd9-90c8-9a7c9c09f088",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/tnvd8_ms5rb8t4jqz9y92c2w0000gn/T/ipykernel_6121/1915639217.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f\"subject_{subj}\"] = 0\n",
      "/var/folders/_f/tnvd8_ms5rb8t4jqz9y92c2w0000gn/T/ipykernel_6121/1915639217.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f\"subject_{subj}\"] = 0\n",
      "/var/folders/_f/tnvd8_ms5rb8t4jqz9y92c2w0000gn/T/ipykernel_6121/1915639217.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f\"subject_{subj}\"] = 0\n",
      "/var/folders/_f/tnvd8_ms5rb8t4jqz9y92c2w0000gn/T/ipykernel_6121/1915639217.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f\"subject_{subj}\"] = 0\n",
      "/var/folders/_f/tnvd8_ms5rb8t4jqz9y92c2w0000gn/T/ipykernel_6121/1915639217.py:3: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[f\"subject_{subj}\"] = 0\n"
     ]
    }
   ],
   "source": [
    "# Inicializar a 0 las columnas dummies\n",
    "for subj in top_subjects:\n",
    "    train_df[f\"subject_{subj}\"] = 0\n",
    "\n",
    "# Asignar 1 si el subject aparece en esa fila\n",
    "def add_subject_dummies(row):\n",
    "    for subj in row[\"processed_subject\"]:\n",
    "        if subj in top_subjects:\n",
    "            row[f\"subject_{subj}\"] = 1\n",
    "    return row\n",
    "\n",
    "train_df = train_df.apply(add_subject_dummies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "07240940-44d9-44a9-afe1-33f4a943fdfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_oil-spill</th>\n",
       "      <th>subject_afghanistan</th>\n",
       "      <th>subject_wealth</th>\n",
       "      <th>subject_china</th>\n",
       "      <th>subject_florida</th>\n",
       "      <th>subject_sexuality</th>\n",
       "      <th>subject_water</th>\n",
       "      <th>subject_population</th>\n",
       "      <th>subject_animals</th>\n",
       "      <th>subject_pensions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new_york</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>with the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>u.s. senator</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6936b216e5d</td>\n",
       "      <td>0</td>\n",
       "      <td>the (wisconsin) governor has proposed tax give...</td>\n",
       "      <td>corporations,pundits,taxes,abc-news-week</td>\n",
       "      <td>donna-brazile</td>\n",
       "      <td>political commentator</td>\n",
       "      <td>washington_dc</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b5cd9195738</td>\n",
       "      <td>1</td>\n",
       "      <td>says her representation of an ex-boyfriend who...</td>\n",
       "      <td>candidates-biography,children,ethics,families,...</td>\n",
       "      <td>rebecca-bradley</td>\n",
       "      <td>non-define</td>\n",
       "      <td>non-define</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>other-political-groups</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84f8dac7737</td>\n",
       "      <td>0</td>\n",
       "      <td>at protests in wisconsin against proposed coll...</td>\n",
       "      <td>health-care,labor,state-budget</td>\n",
       "      <td>republican-party-wisconsin</td>\n",
       "      <td>non-define</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>44edff2b865</td>\n",
       "      <td>1</td>\n",
       "      <td>if rhode island does a hybrid [retirement] pla...</td>\n",
       "      <td>pensions,public-service,retirement,workers</td>\n",
       "      <td>lincoln-chafee</td>\n",
       "      <td>non-define</td>\n",
       "      <td>rhode_island</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>4a63b5f9c16</td>\n",
       "      <td>1</td>\n",
       "      <td>the new health care law will force seniors int...</td>\n",
       "      <td>medicare,message-machine,retirement</td>\n",
       "      <td>dan-coats</td>\n",
       "      <td>non-define</td>\n",
       "      <td>indiana</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>7c57fa8e81c</td>\n",
       "      <td>0</td>\n",
       "      <td>the health insurance plan that (members of con...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>steve-southerland</td>\n",
       "      <td>u.s. representative, florida district 2</td>\n",
       "      <td>florida</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>2375e3cf4b7</td>\n",
       "      <td>1</td>\n",
       "      <td>no one in american history has moved from a ju...</td>\n",
       "      <td>elections,history</td>\n",
       "      <td>newt-gingrich</td>\n",
       "      <td>co-host on cnn's \"crossfire\"</td>\n",
       "      <td>georgia</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>5ae9b14e6e5</td>\n",
       "      <td>0</td>\n",
       "      <td>says the army is spending $7 million to sponso...</td>\n",
       "      <td>federal-budget,military</td>\n",
       "      <td>betty-mccollum</td>\n",
       "      <td>u.s. representative</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8950 rows × 164 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               id  label                                          statement  \\\n",
       "0     81f884c64a7      1  china is in the south china sea and (building)...   \n",
       "1     30c2723a188      0  with the resources it takes to execute just ov...   \n",
       "2     6936b216e5d      0  the (wisconsin) governor has proposed tax give...   \n",
       "3     b5cd9195738      1  says her representation of an ex-boyfriend who...   \n",
       "4     84f8dac7737      0  at protests in wisconsin against proposed coll...   \n",
       "...           ...    ...                                                ...   \n",
       "8945  44edff2b865      1  if rhode island does a hybrid [retirement] pla...   \n",
       "8946  4a63b5f9c16      1  the new health care law will force seniors int...   \n",
       "8947  7c57fa8e81c      0  the health insurance plan that (members of con...   \n",
       "8948  2375e3cf4b7      1  no one in american history has moved from a ju...   \n",
       "8949  5ae9b14e6e5      0  says the army is spending $7 million to sponso...   \n",
       "\n",
       "                                                subject  \\\n",
       "0                         china,foreign-policy,military   \n",
       "1                                           health-care   \n",
       "2              corporations,pundits,taxes,abc-news-week   \n",
       "3     candidates-biography,children,ethics,families,...   \n",
       "4                        health-care,labor,state-budget   \n",
       "...                                                 ...   \n",
       "8945         pensions,public-service,retirement,workers   \n",
       "8946                medicare,message-machine,retirement   \n",
       "8947                                        health-care   \n",
       "8948                                  elections,history   \n",
       "8949                            federal-budget,military   \n",
       "\n",
       "                         speaker                              speaker_job  \\\n",
       "0                   donald-trump                          president-elect   \n",
       "1                     chris-dodd                             u.s. senator   \n",
       "2                  donna-brazile                    political commentator   \n",
       "3                rebecca-bradley                               non-define   \n",
       "4     republican-party-wisconsin                               non-define   \n",
       "...                          ...                                      ...   \n",
       "8945              lincoln-chafee                               non-define   \n",
       "8946                   dan-coats                               non-define   \n",
       "8947           steve-southerland  u.s. representative, florida district 2   \n",
       "8948               newt-gingrich             co-host on cnn's \"crossfire\"   \n",
       "8949              betty-mccollum                      u.s. representative   \n",
       "\n",
       "         state_info party_affiliation party_affiliation_uni  \\\n",
       "0          new_york        republican            republican   \n",
       "1       connecticut          democrat              democrat   \n",
       "2     washington_dc          democrat              democrat   \n",
       "3        non-define              none                  none   \n",
       "4         wisconsin        republican            republican   \n",
       "...             ...               ...                   ...   \n",
       "8945   rhode_island          democrat              democrat   \n",
       "8946        indiana        republican            republican   \n",
       "8947        florida        republican            republican   \n",
       "8948        georgia        republican            republican   \n",
       "8949      minnesota          democrat              democrat   \n",
       "\n",
       "     party_affiliation_category_map  ... subject_oil-spill  \\\n",
       "0             political-affiliation  ...                 0   \n",
       "1             political-affiliation  ...                 0   \n",
       "2             political-affiliation  ...                 0   \n",
       "3            other-political-groups  ...                 0   \n",
       "4             political-affiliation  ...                 0   \n",
       "...                             ...  ...               ...   \n",
       "8945          political-affiliation  ...                 0   \n",
       "8946          political-affiliation  ...                 0   \n",
       "8947          political-affiliation  ...                 0   \n",
       "8948          political-affiliation  ...                 0   \n",
       "8949          political-affiliation  ...                 0   \n",
       "\n",
       "      subject_afghanistan  subject_wealth subject_china subject_florida  \\\n",
       "0                       0               0             1               0   \n",
       "1                       0               0             0               0   \n",
       "2                       0               0             0               0   \n",
       "3                       0               0             0               0   \n",
       "4                       0               0             0               0   \n",
       "...                   ...             ...           ...             ...   \n",
       "8945                    0               0             0               0   \n",
       "8946                    0               0             0               0   \n",
       "8947                    0               0             0               0   \n",
       "8948                    0               0             0               0   \n",
       "8949                    0               0             0               0   \n",
       "\n",
       "     subject_sexuality subject_water subject_population subject_animals  \\\n",
       "0                    0             0                  0               0   \n",
       "1                    0             0                  0               0   \n",
       "2                    0             0                  0               0   \n",
       "3                    0             0                  0               0   \n",
       "4                    0             0                  0               0   \n",
       "...                ...           ...                ...             ...   \n",
       "8945                 0             0                  0               0   \n",
       "8946                 0             0                  0               0   \n",
       "8947                 0             0                  0               0   \n",
       "8948                 0             0                  0               0   \n",
       "8949                 0             0                  0               0   \n",
       "\n",
       "     subject_pensions  \n",
       "0                   0  \n",
       "1                   0  \n",
       "2                   0  \n",
       "3                   0  \n",
       "4                   0  \n",
       "...               ...  \n",
       "8945                1  \n",
       "8946                0  \n",
       "8947                0  \n",
       "8948                0  \n",
       "8949                0  \n",
       "\n",
       "[8950 rows x 164 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b991e763-309a-4ffc-8ace-8c7f60d0347e",
   "metadata": {},
   "source": [
    "Ahora los datos de entrenamiento contienen los temas en formato dummies, más reconocible para catboost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "163bb295-41bb-4877-89d2-5353b5ce05c1",
   "metadata": {},
   "source": [
    "El dataset tiene 100 columnas más, ya que se han seleccionado los 100 topics más hablados. Después de hacer uso de la variable origen, podemos descartarla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "6e10680f-f944-4619-a626-f8c3d32244de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject']"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"processed_subject\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f4434e-181a-4b59-b16c-f015678931ef",
   "metadata": {},
   "source": [
    "### Speaker Job\n",
    "\n",
    "Para speaker job vamos a integrar sus tokens, guardarlos en `speaker_job_text` y usarlos como texto. la variable original no se usará directamente. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "531b9f48-364a-4e0e-ac6d-4404c262bcf8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject',\n",
       " 'speaker_job',\n",
       " 'speaker_entities']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"speaker_job\",\"speaker_entities\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ea5d6bde-af41-4a6d-b936-19abe13ad675",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/tnvd8_ms5rb8t4jqz9y92c2w0000gn/T/ipykernel_6121/2646580810.py:6: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[\"speaker_job_text\"] = train_df[\"speaker_job_tokens\"].apply(lambda x: \" \".join(x))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_afghanistan</th>\n",
       "      <th>subject_wealth</th>\n",
       "      <th>subject_china</th>\n",
       "      <th>subject_florida</th>\n",
       "      <th>subject_sexuality</th>\n",
       "      <th>subject_water</th>\n",
       "      <th>subject_population</th>\n",
       "      <th>subject_animals</th>\n",
       "      <th>subject_pensions</th>\n",
       "      <th>speaker_job_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new_york</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>president - elect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>with the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>u.s. senator</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s . senator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  china is in the south china sea and (building)...   \n",
       "1  30c2723a188      0  with the resources it takes to execute just ov...   \n",
       "\n",
       "                         subject       speaker      speaker_job   state_info  \\\n",
       "0  china,foreign-policy,military  donald-trump  president-elect     new_york   \n",
       "1                    health-care    chris-dodd     u.s. senator  connecticut   \n",
       "\n",
       "  party_affiliation party_affiliation_uni party_affiliation_category_map  ...  \\\n",
       "0        republican            republican          political-affiliation  ...   \n",
       "1          democrat              democrat          political-affiliation  ...   \n",
       "\n",
       "  subject_afghanistan  subject_wealth  subject_china subject_florida  \\\n",
       "0                   0               0              1               0   \n",
       "1                   0               0              0               0   \n",
       "\n",
       "  subject_sexuality subject_water subject_population subject_animals  \\\n",
       "0                 0             0                  0               0   \n",
       "1                 0             0                  0               0   \n",
       "\n",
       "  subject_pensions   speaker_job_text  \n",
       "0                0  president - elect  \n",
       "1                0      u.s . senator  \n",
       "\n",
       "[2 rows x 165 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "# Transformamos a lista\n",
    "train_df[\"speaker_job_tokens\"] = df[\"speaker_job_tokens\"].apply(ast.literal_eval)\n",
    "\n",
    "train_df[\"speaker_job_text\"] = train_df[\"speaker_job_tokens\"].apply(lambda x: \" \".join(x))\n",
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb715f7-e87e-4775-8565-b67bcee4f6c5",
   "metadata": {},
   "source": [
    "La lista de tokens no es procesable para CatBoost, por lo que se elimina del conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3cc151b1-402e-4d46-92c8-ac3508809a3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject',\n",
       " 'speaker_job',\n",
       " 'speaker_entities',\n",
       " 'speaker_job_tokens']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"speaker_job_tokens\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea6f1f-3c25-4a92-b6b5-91510976ebb9",
   "metadata": {},
   "source": [
    "Como `speaker_job_text`es una variable de tipo texto, tenemos que indicárselo a CatBoost como tal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7fe76015-2467-48f1-ad57-770caaea55f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['statement', 'speaker_job_text']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_features += [\"speaker_job_text\"]\n",
    "text_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f11bedf1-9c25-4fe9-a5e1-60be83b84a68",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>subject</th>\n",
       "      <th>speaker</th>\n",
       "      <th>speaker_job</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>party_affiliation_category_map</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_afghanistan</th>\n",
       "      <th>subject_wealth</th>\n",
       "      <th>subject_china</th>\n",
       "      <th>subject_florida</th>\n",
       "      <th>subject_sexuality</th>\n",
       "      <th>subject_water</th>\n",
       "      <th>subject_population</th>\n",
       "      <th>subject_animals</th>\n",
       "      <th>subject_pensions</th>\n",
       "      <th>speaker_job_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>81f884c64a7</td>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>china,foreign-policy,military</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>president-elect</td>\n",
       "      <td>new_york</td>\n",
       "      <td>republican</td>\n",
       "      <td>republican</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>president - elect</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>30c2723a188</td>\n",
       "      <td>0</td>\n",
       "      <td>with the resources it takes to execute just ov...</td>\n",
       "      <td>health-care</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>u.s. senator</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>democrat</td>\n",
       "      <td>democrat</td>\n",
       "      <td>political-affiliation</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s . senator</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 165 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  label                                          statement  \\\n",
       "0  81f884c64a7      1  china is in the south china sea and (building)...   \n",
       "1  30c2723a188      0  with the resources it takes to execute just ov...   \n",
       "\n",
       "                         subject       speaker      speaker_job   state_info  \\\n",
       "0  china,foreign-policy,military  donald-trump  president-elect     new_york   \n",
       "1                    health-care    chris-dodd     u.s. senator  connecticut   \n",
       "\n",
       "  party_affiliation party_affiliation_uni party_affiliation_category_map  ...  \\\n",
       "0        republican            republican          political-affiliation  ...   \n",
       "1          democrat              democrat          political-affiliation  ...   \n",
       "\n",
       "  subject_afghanistan  subject_wealth  subject_china subject_florida  \\\n",
       "0                   0               0              1               0   \n",
       "1                   0               0              0               0   \n",
       "\n",
       "  subject_sexuality subject_water subject_population subject_animals  \\\n",
       "0                 0             0                  0               0   \n",
       "1                 0             0                  0               0   \n",
       "\n",
       "  subject_pensions   speaker_job_text  \n",
       "0                0  president - elect  \n",
       "1                0      u.s . senator  \n",
       "\n",
       "[2 rows x 165 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad901a8-0d2f-4017-8a7e-2773beabe312",
   "metadata": {},
   "source": [
    "### State info\n",
    "\n",
    "Es una variable puramente categórica, ya procesada y con interés predictivo. Se añade a la lista de features categóricas. `state_info_tokens` contiene la misma información, se descarta. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7b4f64cb-ef05-4a62-955e-d4c441acbc44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_info']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features = [\"state_info\"]\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dfb0f423-9d43-4417-93d2-83fc3fb09721",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject',\n",
       " 'speaker_job',\n",
       " 'speaker_entities',\n",
       " 'speaker_job_tokens',\n",
       " 'state_info_tokens']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"state_info_tokens\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "22143932-7834-4516-ae35-666fb9b37c4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"state_info\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb59c5f-b543-4528-91b9-42a596f72782",
   "metadata": {},
   "source": [
    "Comprobamos que quizás la cardinalidad es demasiado alta. Posible reducción."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e45c0b2f-0807-4481-ba31-679006a08d1e",
   "metadata": {},
   "source": [
    "### Party_affiliation\n",
    "\n",
    "Tenemos tres variables que hacen referencia a esta información:\n",
    "- `party_affiliation`: variable original sin limpiar, se descarta.\n",
    "- `party_affiliation_uni`: variable procesada, observar cardinalidad.\n",
    "- `party_afiliation_category_map`: variable mapeada manualmente, comparar rendimiento con la anterior.\n",
    "- `party_affiliation_tokens`: versión tokenizada, se quita\n",
    "\n",
    "Descartamos la original:    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "20228663-17c4-489c-ae25-fe4f38b42a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject',\n",
       " 'speaker_job',\n",
       " 'speaker_entities',\n",
       " 'speaker_job_tokens',\n",
       " 'state_info_tokens',\n",
       " 'party_affiliation',\n",
       " 'party_affiliation_tokens']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"party_affiliation\",\"party_affiliation_tokens\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0afbba93-82d6-46e6-ba5f-743370a09051",
   "metadata": {},
   "source": [
    "Contamos los valores únicos en `_uni`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "3732d6f2-09cd-4417-8fd8-53b1a878eab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"party_affiliation_uni\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e089903-dbd8-4004-b8b4-7b1376f77752",
   "metadata": {},
   "source": [
    "Se trata de un valor aceptable para pasarlo como categórica al modelo. Se añade."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "596bedc4-dfc0-41f4-90af-81405bbda83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_info', 'party_affiliation_uni']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features+=[\"party_affiliation_uni\"]\n",
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "6266ae00-498c-4ec2-a3b6-ee0824f972a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"party_affiliation_category_map\"].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2daea7c7-7d1b-42e3-bc90-288a8823b784",
   "metadata": {},
   "source": [
    "Dado que la cardinalidad de `_uni` es adecuada y esta variable viene de un mapeo manual, se elimina del modelo provisionalmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "01fdac2f-67cf-4f58-96e4-d4aab8222170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject',\n",
       " 'speaker_job',\n",
       " 'speaker_entities',\n",
       " 'speaker_job_tokens',\n",
       " 'state_info_tokens',\n",
       " 'party_affiliation',\n",
       " 'party_affiliation_tokens',\n",
       " 'party_affiliation_category_map']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"party_affiliation_category_map\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2359fabf-7d7e-48c0-891f-16fa1644ead3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'label', 'statement', 'subject', 'speaker', 'speaker_job',\n",
       "       'state_info', 'party_affiliation', 'party_affiliation_uni',\n",
       "       'party_affiliation_category_map', 'statement_tokens', 'num_tokens',\n",
       "       'num_sentences', 'pos_info', 'pos_freq', 'lemma_freq', 'tag_freq',\n",
       "       'entities', 'stopwords', 'statement_tokens_without_stopwords',\n",
       "       'num_tokens_without_stopwords', 'pos_info_without_stopwords',\n",
       "       'pos_freq_without_stopwords', 'lemma_freq_without_stopwords',\n",
       "       'tag_freq_without_stopwords', 'processed_subject', 'speaker_entities',\n",
       "       'speaker_type', 'speaker_job_tokens', 'state_info_tokens',\n",
       "       'party_affiliation_tokens'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a946f-8e6f-4289-9eb7-d89de7aad418",
   "metadata": {},
   "source": [
    "### Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6608be3c-1553-4188-9462-e4bfd66d39a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         Entidad Tipo de Entidad                Expli...\n",
       "1                         Entidad Tipo de Entidad  \\\\n...\n",
       "2                 Entidad Tipo de Entidad             ...\n",
       "3       Empty DataFrame\\nColumns: [Entidad, Tipo de En...\n",
       "4            Entidad Tipo de Entidad                Ex...\n",
       "                              ...                        \n",
       "8945            Entidad Tipo de Entidad               ...\n",
       "8946                       Entidad Tipo de Entidad  \\\\...\n",
       "8947                 Entidad Tipo de Entidad          ...\n",
       "8948                  Entidad Tipo de Entidad  \\\\n0   ...\n",
       "8949          Entidad Tipo de Entidad                 ...\n",
       "Name: entities, Length: 8950, dtype: object"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"entities\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "0aeb9e7a-c386-4a42-a0bd-c47d0c10a840",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/tnvd8_ms5rb8t4jqz9y92c2w0000gn/T/ipykernel_6121/680811948.py:20: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  train_df[\"entity_list\"] = df[\"entities\"].apply(extract_entities)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                                [GPE]\n",
       "1                [DATE, EVENT, PERSON]\n",
       "2                                [ORG]\n",
       "3                              [OTHER]\n",
       "4                                [GPE]\n",
       "                     ...              \n",
       "8945                    [GPE, ORDINAL]\n",
       "8946                             [ORG]\n",
       "8947                        [ORG, GPE]\n",
       "8948    [NORP, DATE, CARDINAL, PERSON]\n",
       "8949                           [MONEY]\n",
       "Name: entity_list, Length: 8950, dtype: object"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def extract_entities(entity_str):\n",
    "    if not isinstance(entity_str, str) or \"Tipo de Entidad\" not in entity_str:\n",
    "        return []\n",
    "\n",
    "    try:\n",
    "        lines = entity_str.strip().split(\"\\n\")\n",
    "        lines = lines[1:]\n",
    "        entities = []\n",
    "        for line in lines:\n",
    "                matches = re.findall(r\"\\b\\w*[A-Z]{3,}\\w*\\b\", line)\n",
    "                if matches:\n",
    "                    entities+=matches\n",
    "        return entities if entities else [\"OTHER\"]\n",
    "    except:\n",
    "        return []\n",
    "\n",
    "# Aplicar al DataFrame\n",
    "train_df[\"entity_list\"] = df[\"entities\"].apply(extract_entities)\n",
    "train_df[\"entity_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "45ff874a-1efb-4d6e-9c8a-46069b4e32ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_CARDINAL</th>\n",
       "      <th>entity_DATE</th>\n",
       "      <th>entity_EVENT</th>\n",
       "      <th>entity_FAC</th>\n",
       "      <th>entity_GPE</th>\n",
       "      <th>entity_LANGUAGE</th>\n",
       "      <th>entity_LAW</th>\n",
       "      <th>entity_LOC</th>\n",
       "      <th>entity_MONEY</th>\n",
       "      <th>entity_NORP</th>\n",
       "      <th>entity_ORDINAL</th>\n",
       "      <th>entity_ORG</th>\n",
       "      <th>entity_OTHER</th>\n",
       "      <th>entity_PERCENT</th>\n",
       "      <th>entity_PERSON</th>\n",
       "      <th>entity_PRODUCT</th>\n",
       "      <th>entity_QUANTITY</th>\n",
       "      <th>entity_TIME</th>\n",
       "      <th>entity_WORK_OF_ART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8950 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity_CARDINAL  entity_DATE  entity_EVENT  entity_FAC  entity_GPE  \\\n",
       "0                   0            0             0           0           1   \n",
       "1                   0            1             1           0           0   \n",
       "2                   0            0             0           0           0   \n",
       "3                   0            0             0           0           0   \n",
       "4                   0            0             0           0           1   \n",
       "...               ...          ...           ...         ...         ...   \n",
       "8945                0            0             0           0           1   \n",
       "8946                0            0             0           0           0   \n",
       "8947                0            0             0           0           1   \n",
       "8948                1            1             0           0           0   \n",
       "8949                0            0             0           0           0   \n",
       "\n",
       "      entity_LANGUAGE  entity_LAW  entity_LOC  entity_MONEY  entity_NORP  \\\n",
       "0                   0           0           0             0            0   \n",
       "1                   0           0           0             0            0   \n",
       "2                   0           0           0             0            0   \n",
       "3                   0           0           0             0            0   \n",
       "4                   0           0           0             0            0   \n",
       "...               ...         ...         ...           ...          ...   \n",
       "8945                0           0           0             0            0   \n",
       "8946                0           0           0             0            0   \n",
       "8947                0           0           0             0            0   \n",
       "8948                0           0           0             0            1   \n",
       "8949                0           0           0             1            0   \n",
       "\n",
       "      entity_ORDINAL  entity_ORG  entity_OTHER  entity_PERCENT  entity_PERSON  \\\n",
       "0                  0           0             0               0              0   \n",
       "1                  0           0             0               0              1   \n",
       "2                  0           1             0               0              0   \n",
       "3                  0           0             1               0              0   \n",
       "4                  0           0             0               0              0   \n",
       "...              ...         ...           ...             ...            ...   \n",
       "8945               1           0             0               0              0   \n",
       "8946               0           1             0               0              0   \n",
       "8947               0           1             0               0              0   \n",
       "8948               0           0             0               0              1   \n",
       "8949               0           0             0               0              0   \n",
       "\n",
       "      entity_PRODUCT  entity_QUANTITY  entity_TIME  entity_WORK_OF_ART  \n",
       "0                  0                0            0                   0  \n",
       "1                  0                0            0                   0  \n",
       "2                  0                0            0                   0  \n",
       "3                  0                0            0                   0  \n",
       "4                  0                0            0                   0  \n",
       "...              ...              ...          ...                 ...  \n",
       "8945               0                0            0                   0  \n",
       "8946               0                0            0                   0  \n",
       "8947               0                0            0                   0  \n",
       "8948               0                0            0                   0  \n",
       "8949               0                0            0                   0  \n",
       "\n",
       "[8950 rows x 19 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "train_df[\"entity_list\"] = train_df[\"entity_list\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Binarizar\n",
    "mlb = MultiLabelBinarizer()\n",
    "entity_dummies = pd.DataFrame(\n",
    "    mlb.fit_transform(train_df[\"entity_list\"]),\n",
    "    columns=[f\"entity_{cls}\" for cls in mlb.classes_],\n",
    "    index=train_df.index\n",
    ")\n",
    "\n",
    "entity_counts = entity_dummies.sum().sort_values(ascending=False)\n",
    "entity_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "80f4f09d-5f3a-4929-a652-d960d811fdf3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_type</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>entity_PERSON</td>\n",
       "      <td>2690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>entity_GPE</td>\n",
       "      <td>2689</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>entity_DATE</td>\n",
       "      <td>1943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>entity_CARDINAL</td>\n",
       "      <td>1869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>entity_OTHER</td>\n",
       "      <td>1331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>entity_ORG</td>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>entity_NORP</td>\n",
       "      <td>1077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>entity_MONEY</td>\n",
       "      <td>1075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>entity_PERCENT</td>\n",
       "      <td>924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>entity_ORDINAL</td>\n",
       "      <td>361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>entity_LOC</td>\n",
       "      <td>94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>entity_TIME</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>entity_QUANTITY</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>entity_EVENT</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>entity_FAC</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>entity_LANGUAGE</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>entity_PRODUCT</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>entity_LAW</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>entity_WORK_OF_ART</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           entity_type  frequency\n",
       "0        entity_PERSON       2690\n",
       "1           entity_GPE       2689\n",
       "2          entity_DATE       1943\n",
       "3      entity_CARDINAL       1869\n",
       "4         entity_OTHER       1331\n",
       "5           entity_ORG       1296\n",
       "6          entity_NORP       1077\n",
       "7         entity_MONEY       1075\n",
       "8       entity_PERCENT        924\n",
       "9       entity_ORDINAL        361\n",
       "10          entity_LOC         94\n",
       "11         entity_TIME         67\n",
       "12     entity_QUANTITY         64\n",
       "13        entity_EVENT         41\n",
       "14          entity_FAC         31\n",
       "15     entity_LANGUAGE         12\n",
       "16      entity_PRODUCT          9\n",
       "17          entity_LAW          7\n",
       "18  entity_WORK_OF_ART          1"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_freq_df = entity_counts.reset_index()\n",
    "entity_freq_df.columns = [\"entity_type\", \"frequency\"]\n",
    "entity_freq_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0a1bbd-e7db-4363-a01d-6e3afbcaa5a8",
   "metadata": {},
   "source": [
    "Reducir cardinalidad para no meter ruido. Para ello, vamos a quedarnos con 10 características (después de observar su frecuencia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7ec852c9-7cb7-4f3a-840f-766ed99f9953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entidades frecuentes (a conservar):\n",
      "['entity_PERSON', 'entity_GPE', 'entity_DATE', 'entity_CARDINAL', 'entity_OTHER', 'entity_ORG', 'entity_NORP', 'entity_MONEY', 'entity_PERCENT', 'entity_ORDINAL']\n",
      "Entidades poco frecuentes (a eliminar):\n",
      "['entity_LOC', 'entity_TIME', 'entity_QUANTITY', 'entity_EVENT', 'entity_FAC', 'entity_LANGUAGE', 'entity_PRODUCT', 'entity_LAW', 'entity_WORK_OF_ART']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_CARDINAL</th>\n",
       "      <th>entity_DATE</th>\n",
       "      <th>entity_EVENT</th>\n",
       "      <th>entity_FAC</th>\n",
       "      <th>entity_GPE</th>\n",
       "      <th>entity_LANGUAGE</th>\n",
       "      <th>entity_LAW</th>\n",
       "      <th>entity_LOC</th>\n",
       "      <th>entity_MONEY</th>\n",
       "      <th>entity_NORP</th>\n",
       "      <th>entity_ORDINAL</th>\n",
       "      <th>entity_ORG</th>\n",
       "      <th>entity_OTHER</th>\n",
       "      <th>entity_PERCENT</th>\n",
       "      <th>entity_PERSON</th>\n",
       "      <th>entity_PRODUCT</th>\n",
       "      <th>entity_QUANTITY</th>\n",
       "      <th>entity_TIME</th>\n",
       "      <th>entity_WORK_OF_ART</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8950 rows × 19 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      entity_CARDINAL  entity_DATE  entity_EVENT  entity_FAC  entity_GPE  \\\n",
       "0                   0            0             0           0           1   \n",
       "1                   0            1             1           0           0   \n",
       "2                   0            0             0           0           0   \n",
       "3                   0            0             0           0           0   \n",
       "4                   0            0             0           0           1   \n",
       "...               ...          ...           ...         ...         ...   \n",
       "8945                0            0             0           0           1   \n",
       "8946                0            0             0           0           0   \n",
       "8947                0            0             0           0           1   \n",
       "8948                1            1             0           0           0   \n",
       "8949                0            0             0           0           0   \n",
       "\n",
       "      entity_LANGUAGE  entity_LAW  entity_LOC  entity_MONEY  entity_NORP  \\\n",
       "0                   0           0           0             0            0   \n",
       "1                   0           0           0             0            0   \n",
       "2                   0           0           0             0            0   \n",
       "3                   0           0           0             0            0   \n",
       "4                   0           0           0             0            0   \n",
       "...               ...         ...         ...           ...          ...   \n",
       "8945                0           0           0             0            0   \n",
       "8946                0           0           0             0            0   \n",
       "8947                0           0           0             0            0   \n",
       "8948                0           0           0             0            1   \n",
       "8949                0           0           0             1            0   \n",
       "\n",
       "      entity_ORDINAL  entity_ORG  entity_OTHER  entity_PERCENT  entity_PERSON  \\\n",
       "0                  0           0             0               0              0   \n",
       "1                  0           0             1               0              1   \n",
       "2                  0           1             0               0              0   \n",
       "3                  0           0             0               0              0   \n",
       "4                  0           0             0               0              0   \n",
       "...              ...         ...           ...             ...            ...   \n",
       "8945               1           0             0               0              0   \n",
       "8946               0           1             0               0              0   \n",
       "8947               0           1             0               0              0   \n",
       "8948               0           0             0               0              1   \n",
       "8949               0           0             0               0              0   \n",
       "\n",
       "      entity_PRODUCT  entity_QUANTITY  entity_TIME  entity_WORK_OF_ART  \n",
       "0                  0                0            0                   0  \n",
       "1                  0                0            0                   0  \n",
       "2                  0                0            0                   0  \n",
       "3                  0                0            0                   0  \n",
       "4                  0                0            0                   0  \n",
       "...              ...              ...          ...                 ...  \n",
       "8945               0                0            0                   0  \n",
       "8946               0                0            0                   0  \n",
       "8947               0                0            0                   0  \n",
       "8948               0                0            0                   0  \n",
       "8949               0                0            0                   0  \n",
       "\n",
       "[8950 rows x 19 columns]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Definir umbral \n",
    "threshold = 100\n",
    "entities_to_keep = entity_freq_df[entity_freq_df[\"frequency\"] >= threshold][\"entity_type\"].tolist()\n",
    "entities_to_drop = entity_freq_df[entity_freq_df[\"frequency\"] < threshold][\"entity_type\"].tolist()\n",
    "\n",
    "# Mostrar\n",
    "print(\"Entidades frecuentes (a conservar):\")\n",
    "print(entities_to_keep)\n",
    "print(\"Entidades poco frecuentes (a eliminar):\")\n",
    "print(entities_to_drop)\n",
    "\n",
    "# Crear nueva columna 'entity_OTHER' en entity_dummies\n",
    "entity_dummies[\"entity_OTHER\"] = entity_dummies[entities_to_drop].any(axis=1).astype(int)\n",
    "entity_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "f742ecc8-5ec1-49e9-aef6-d234da44efd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject',\n",
       " 'speaker_job',\n",
       " 'speaker_entities',\n",
       " 'speaker_job_tokens',\n",
       " 'state_info_tokens',\n",
       " 'party_affiliation',\n",
       " 'party_affiliation_tokens',\n",
       " 'party_affiliation_category_map',\n",
       " 'entities',\n",
       " 'entity_list']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "drop_cols += [\"entities\",\"entity_list\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b91309-23d8-480a-9b07-2ab6aeeaf92a",
   "metadata": {},
   "source": [
    "### Speaker_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "6c83fdb1-13c9-4f4a-bcb1-04c8511c1559",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "train_df[\"speaker_type\"] = df[\"speaker_type\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else (x if isinstance(x, list) else [])\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "961fda44-44c1-489c-bd4b-124a5627b278",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         [PERSON]\n",
       "1         [PERSON]\n",
       "2         [PERSON]\n",
       "3         [PERSON]\n",
       "4       [ORG, GPE]\n",
       "           ...    \n",
       "8945         [ORG]\n",
       "8946      [PERSON]\n",
       "8947      [PERSON]\n",
       "8948      [PERSON]\n",
       "8949      [PERSON]\n",
       "Name: speaker_type, Length: 8950, dtype: object"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[\"speaker_type\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "a4390378-b007-46c4-ae4a-7b14a2ae73c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "speaker_type_PERSON      5995\n",
       "speaker_type_ORG          780\n",
       "speaker_type_GPE          264\n",
       "speaker_type_NORP         188\n",
       "speaker_type_CARDINAL      41\n",
       "speaker_type_DATE          16\n",
       "speaker_type_PRODUCT       13\n",
       "speaker_type_ORDINAL        7\n",
       "speaker_type_FAC            7\n",
       "speaker_type_EVENT          4\n",
       "speaker_type_PERCENT        2\n",
       "speaker_type_LAW            1\n",
       "speaker_type_TIME           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Binarizar\n",
    "mlb = MultiLabelBinarizer()\n",
    "speaker_type_dummies = pd.DataFrame(\n",
    "    mlb.fit_transform(train_df[\"speaker_type\"]),\n",
    "    columns=[f\"speaker_type_{cls}\" for cls in mlb.classes_],\n",
    "    index=train_df.index\n",
    ")\n",
    "\n",
    "speaker_type_counts = speaker_type_dummies.sum().sort_values(ascending=False)\n",
    "speaker_type_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "91c59673-3e83-4b95-869f-3966d63d87da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>entity_type</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>speaker_type_PERSON</td>\n",
       "      <td>5995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>speaker_type_ORG</td>\n",
       "      <td>780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>speaker_type_GPE</td>\n",
       "      <td>264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>speaker_type_NORP</td>\n",
       "      <td>188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>speaker_type_CARDINAL</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>speaker_type_DATE</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>speaker_type_PRODUCT</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>speaker_type_ORDINAL</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>speaker_type_FAC</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>speaker_type_EVENT</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>speaker_type_PERCENT</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>speaker_type_LAW</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>speaker_type_TIME</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              entity_type  frequency\n",
       "0     speaker_type_PERSON       5995\n",
       "1        speaker_type_ORG        780\n",
       "2        speaker_type_GPE        264\n",
       "3       speaker_type_NORP        188\n",
       "4   speaker_type_CARDINAL         41\n",
       "5       speaker_type_DATE         16\n",
       "6    speaker_type_PRODUCT         13\n",
       "7    speaker_type_ORDINAL          7\n",
       "8        speaker_type_FAC          7\n",
       "9      speaker_type_EVENT          4\n",
       "10   speaker_type_PERCENT          2\n",
       "11       speaker_type_LAW          1\n",
       "12      speaker_type_TIME          1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_type_freq = speaker_type_counts.reset_index()\n",
    "speaker_type_freq.columns = [\"entity_type\", \"frequency\"]\n",
    "speaker_type_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89328c16-5739-4d35-83d0-9fe38c8f7f96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speakers frecuentes (a conservar):\n",
      "['speaker_type_PERSON', 'speaker_type_ORG', 'speaker_type_GPE', 'speaker_type_NORP']\n",
      "speakers poco frecuentes (a eliminar):\n",
      "['speaker_type_CARDINAL', 'speaker_type_DATE', 'speaker_type_PRODUCT', 'speaker_type_ORDINAL', 'speaker_type_FAC', 'speaker_type_EVENT', 'speaker_type_PERCENT', 'speaker_type_LAW', 'speaker_type_TIME']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>speaker_type_GPE</th>\n",
       "      <th>speaker_type_NORP</th>\n",
       "      <th>speaker_type_ORG</th>\n",
       "      <th>speaker_type_PERSON</th>\n",
       "      <th>speaker_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8950 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      speaker_type_GPE  speaker_type_NORP  speaker_type_ORG  \\\n",
       "0                    0                  0                 0   \n",
       "1                    0                  0                 0   \n",
       "2                    0                  0                 0   \n",
       "3                    0                  0                 0   \n",
       "4                    1                  0                 1   \n",
       "...                ...                ...               ...   \n",
       "8945                 0                  0                 1   \n",
       "8946                 0                  0                 0   \n",
       "8947                 0                  0                 0   \n",
       "8948                 0                  0                 0   \n",
       "8949                 0                  0                 0   \n",
       "\n",
       "      speaker_type_PERSON  speaker_OTHER  \n",
       "0                       1              0  \n",
       "1                       1              0  \n",
       "2                       1              0  \n",
       "3                       1              0  \n",
       "4                       0              0  \n",
       "...                   ...            ...  \n",
       "8945                    0              0  \n",
       "8946                    1              0  \n",
       "8947                    1              0  \n",
       "8948                    1              0  \n",
       "8949                    1              0  \n",
       "\n",
       "[8950 rows x 5 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Definir umbral \n",
    "threshold = 100\n",
    "speaker_to_keep = speaker_type_freq[speaker_type_freq[\"frequency\"] >= threshold][\"entity_type\"].tolist()\n",
    "speaker_to_drop = speaker_type_freq[speaker_type_freq[\"frequency\"] < threshold][\"entity_type\"].tolist()\n",
    "\n",
    "# Mostrar\n",
    "print(\"Speakers frecuentes (a conservar):\")\n",
    "print(speaker_to_keep)\n",
    "print(\"speakers poco frecuentes (a eliminar):\")\n",
    "print(speaker_to_drop)\n",
    "\n",
    "# Crear nueva columna 'entity_OTHER' en speaker_dummies\n",
    "speaker_type_dummies[\"speaker_OTHER\"] = speaker_type_dummies[speaker_to_drop].any(axis=1).astype(int)\n",
    "speaker_type_dummies = speaker_type_dummies.drop(columns=speaker_to_drop)\n",
    "speaker_type_dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "40388e21-c498-49b2-b551-3cc6d7bba944",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['id',\n",
       " 'statement_tokens',\n",
       " 'statement_tokens_without_stopwords',\n",
       " 'stopwords',\n",
       " 'num_tokens_without_stopwords',\n",
       " 'num_sentences',\n",
       " 'pos_info',\n",
       " 'pos_freq',\n",
       " 'pos_freq_without_stopwords',\n",
       " 'pos_info_without_stopwords',\n",
       " 'lemma_freq',\n",
       " 'tag_freq',\n",
       " 'lemma_freq_without_stopwords',\n",
       " 'tag_freq_without_stopwords',\n",
       " 'subject',\n",
       " 'processed_subject',\n",
       " 'speaker_job',\n",
       " 'speaker_entities',\n",
       " 'speaker_job_tokens',\n",
       " 'state_info_tokens',\n",
       " 'party_affiliation',\n",
       " 'party_affiliation_tokens',\n",
       " 'party_affiliation_category_map',\n",
       " 'entities',\n",
       " 'entity_list',\n",
       " 'speaker_type']"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.concat([train_df,speaker_type_dummies],axis=1)\n",
    "drop_cols += [\"speaker_type\"]\n",
    "drop_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "477660a5-76a4-43fc-b77d-1c5f471592f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8950, 171)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "4e2351b9-d81f-4bab-9131-ae26d46da816",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df.drop(columns=drop_cols)\n",
    "#train_df = train_df.drop(columns=[\"statement_tokens_without_stopwords\"])\n",
    "\n",
    "#train_df[\"num_stopwords_tokens\"] = train_df[\"num_tokens\"] - train_df[\"num_tokens_without_stopwords\"]\n",
    "#train_df = train_df.drop(columns=[\"num_tokens_without_stopwords\"])\n",
    "#train_df = train_df.drop(columns=[\"num_sentences\"])\n",
    "#train_df = train_df.drop(columns=[\"lemma_freq_without_stopwords\",\"tag_freq_without_stopwords\"])\n",
    "#train_df = train_df.drop(columns=[\"stopwords\"])\n",
    "#train_df = train_df.drop(columns=[\"speaker_entities\"])\n",
    "#train_df = train_df.drop(columns=[\"state_info_tokens\"])\n",
    "#train_df = train_df.drop(columns=[\"party_affiliation_tokens\"])\n",
    "#train_df = train_df.drop(columns=[\"speaker\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c6e205fd-d0ee-4dbd-983a-1d3484c28c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['state_info', 'party_affiliation_uni']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "4d6e534a-9d5b-4b47-acb8-f0199a55bca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clasificar columnas por tipo\n",
    "import pandas as pd\n",
    "\n",
    "# 1. Columnas numéricas\n",
    "numeric_cols = train_df.select_dtypes(include=[\"int64\", \"float64\"]).columns.tolist()\n",
    "\n",
    "# 2. Columnas categóricas (tipo object o category con pocos valores únicos)\n",
    "categorical_cols = train_df.select_dtypes(include=[\"object\", \"category\", \"bool\"]).columns.tolist()\n",
    "\n",
    "# 3. Detectar columnas de texto: muchas categorías únicas y tipo str\n",
    "text_cols = [col for col in categorical_cols if train_df[col].nunique() > 30 and train_df[col].apply(lambda x: isinstance(x, str)).all()]\n",
    "\n",
    "# 4. Excluir columnas de texto de las categóricas\n",
    "categorical_cols = [col for col in categorical_cols if col not in text_cols]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "ccad6add-a0f2-418c-ad64-ef8f7054bb5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>statement</th>\n",
       "      <th>speaker</th>\n",
       "      <th>state_info</th>\n",
       "      <th>party_affiliation_uni</th>\n",
       "      <th>num_tokens</th>\n",
       "      <th>num_stopwords_tokens</th>\n",
       "      <th>pos_PROPN</th>\n",
       "      <th>pos_NOUN</th>\n",
       "      <th>pos_ADJ</th>\n",
       "      <th>...</th>\n",
       "      <th>subject_water</th>\n",
       "      <th>subject_population</th>\n",
       "      <th>subject_animals</th>\n",
       "      <th>subject_pensions</th>\n",
       "      <th>speaker_job_text</th>\n",
       "      <th>speaker_type_GPE</th>\n",
       "      <th>speaker_type_NORP</th>\n",
       "      <th>speaker_type_ORG</th>\n",
       "      <th>speaker_type_PERSON</th>\n",
       "      <th>speaker_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>china is in the south china sea and (building)...</td>\n",
       "      <td>donald-trump</td>\n",
       "      <td>new_york</td>\n",
       "      <td>republican</td>\n",
       "      <td>23</td>\n",
       "      <td>13</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>president - elect</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>with the resources it takes to execute just ov...</td>\n",
       "      <td>chris-dodd</td>\n",
       "      <td>connecticut</td>\n",
       "      <td>democrat</td>\n",
       "      <td>32</td>\n",
       "      <td>17</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s . senator</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>the (wisconsin) governor has proposed tax give...</td>\n",
       "      <td>donna-brazile</td>\n",
       "      <td>washington_dc</td>\n",
       "      <td>democrat</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>political commentator</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>says her representation of an ex-boyfriend who...</td>\n",
       "      <td>rebecca-bradley</td>\n",
       "      <td>non-define</td>\n",
       "      <td>none</td>\n",
       "      <td>28</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non - define</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>at protests in wisconsin against proposed coll...</td>\n",
       "      <td>republican-party-wisconsin</td>\n",
       "      <td>wisconsin</td>\n",
       "      <td>republican</td>\n",
       "      <td>24</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non - define</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8945</th>\n",
       "      <td>1</td>\n",
       "      <td>if rhode island does a hybrid [retirement] pla...</td>\n",
       "      <td>lincoln-chafee</td>\n",
       "      <td>rhode_island</td>\n",
       "      <td>democrat</td>\n",
       "      <td>22</td>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>non - define</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8946</th>\n",
       "      <td>1</td>\n",
       "      <td>the new health care law will force seniors int...</td>\n",
       "      <td>dan-coats</td>\n",
       "      <td>indiana</td>\n",
       "      <td>republican</td>\n",
       "      <td>18</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>non - define</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8947</th>\n",
       "      <td>0</td>\n",
       "      <td>the health insurance plan that (members of con...</td>\n",
       "      <td>steve-southerland</td>\n",
       "      <td>florida</td>\n",
       "      <td>republican</td>\n",
       "      <td>25</td>\n",
       "      <td>14</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s . representative , florida district 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8948</th>\n",
       "      <td>1</td>\n",
       "      <td>no one in american history has moved from a ju...</td>\n",
       "      <td>newt-gingrich</td>\n",
       "      <td>georgia</td>\n",
       "      <td>republican</td>\n",
       "      <td>26</td>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>co - host on cnn 's \" crossfire \"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8949</th>\n",
       "      <td>0</td>\n",
       "      <td>says the army is spending $7 million to sponso...</td>\n",
       "      <td>betty-mccollum</td>\n",
       "      <td>minnesota</td>\n",
       "      <td>democrat</td>\n",
       "      <td>14</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>u.s . representative</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8950 rows × 145 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                          statement  \\\n",
       "0         1  china is in the south china sea and (building)...   \n",
       "1         0  with the resources it takes to execute just ov...   \n",
       "2         0  the (wisconsin) governor has proposed tax give...   \n",
       "3         1  says her representation of an ex-boyfriend who...   \n",
       "4         0  at protests in wisconsin against proposed coll...   \n",
       "...     ...                                                ...   \n",
       "8945      1  if rhode island does a hybrid [retirement] pla...   \n",
       "8946      1  the new health care law will force seniors int...   \n",
       "8947      0  the health insurance plan that (members of con...   \n",
       "8948      1  no one in american history has moved from a ju...   \n",
       "8949      0  says the army is spending $7 million to sponso...   \n",
       "\n",
       "                         speaker     state_info party_affiliation_uni  \\\n",
       "0                   donald-trump       new_york            republican   \n",
       "1                     chris-dodd    connecticut              democrat   \n",
       "2                  donna-brazile  washington_dc              democrat   \n",
       "3                rebecca-bradley     non-define                  none   \n",
       "4     republican-party-wisconsin      wisconsin            republican   \n",
       "...                          ...            ...                   ...   \n",
       "8945              lincoln-chafee   rhode_island              democrat   \n",
       "8946                   dan-coats        indiana            republican   \n",
       "8947           steve-southerland        florida            republican   \n",
       "8948               newt-gingrich        georgia            republican   \n",
       "8949              betty-mccollum      minnesota              democrat   \n",
       "\n",
       "      num_tokens  num_stopwords_tokens  pos_PROPN  pos_NOUN  pos_ADJ  ...  \\\n",
       "0             23                    13          4         4        1  ...   \n",
       "1             32                    17          2         7        1  ...   \n",
       "2             12                     6          1         4        0  ...   \n",
       "3             28                    17          0         9        1  ...   \n",
       "4             24                    10          0         7        3  ...   \n",
       "...          ...                   ...        ...       ...      ...  ...   \n",
       "8945          22                    15          2         4        1  ...   \n",
       "8946          18                     5          0         8        2  ...   \n",
       "8947          25                    14          3         6        2  ...   \n",
       "8948          26                    16          1         5        2  ...   \n",
       "8949          14                     6          0         3        0  ...   \n",
       "\n",
       "      subject_water  subject_population  subject_animals  subject_pensions  \\\n",
       "0                 0                   0                0                 0   \n",
       "1                 0                   0                0                 0   \n",
       "2                 0                   0                0                 0   \n",
       "3                 0                   0                0                 0   \n",
       "4                 0                   0                0                 0   \n",
       "...             ...                 ...              ...               ...   \n",
       "8945              0                   0                0                 1   \n",
       "8946              0                   0                0                 0   \n",
       "8947              0                   0                0                 0   \n",
       "8948              0                   0                0                 0   \n",
       "8949              0                   0                0                 0   \n",
       "\n",
       "                               speaker_job_text  speaker_type_GPE  \\\n",
       "0                             president - elect                 0   \n",
       "1                                 u.s . senator                 0   \n",
       "2                         political commentator                 0   \n",
       "3                                  non - define                 0   \n",
       "4                                  non - define                 1   \n",
       "...                                         ...               ...   \n",
       "8945                               non - define                 0   \n",
       "8946                               non - define                 0   \n",
       "8947  u.s . representative , florida district 2                 0   \n",
       "8948          co - host on cnn 's \" crossfire \"                 0   \n",
       "8949                       u.s . representative                 0   \n",
       "\n",
       "      speaker_type_NORP  speaker_type_ORG  speaker_type_PERSON  speaker_OTHER  \n",
       "0                     0                 0                    1              0  \n",
       "1                     0                 0                    1              0  \n",
       "2                     0                 0                    1              0  \n",
       "3                     0                 0                    1              0  \n",
       "4                     0                 1                    0              0  \n",
       "...                 ...               ...                  ...            ...  \n",
       "8945                  0                 1                    0              0  \n",
       "8946                  0                 0                    1              0  \n",
       "8947                  0                 0                    1              0  \n",
       "8948                  0                 0                    1              0  \n",
       "8949                  0                 0                    1              0  \n",
       "\n",
       "[8950 rows x 145 columns]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6066baf-2fa6-4f12-9ac5-db7da73be7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 20 candidates, totalling 100 fits\n",
      "0:\tlearn: 0.6923013\ttotal: 191ms\tremaining: 3m 10s\n",
      "100:\tlearn: 0.6569140\ttotal: 19.2s\tremaining: 2m 51s\n",
      "200:\tlearn: 0.6375651\ttotal: 32.8s\tremaining: 2m 10s\n",
      "300:\tlearn: 0.6041446\ttotal: 47.7s\tremaining: 1m 50s\n",
      "400:\tlearn: 0.5730324\ttotal: 1m 1s\tremaining: 1m 32s\n"
     ]
    }
   ],
   "source": [
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Supongamos que tu variable objetivo se llama 'label'\n",
    "X = train_df.drop(columns=[\"label\",\"speaker\"])\n",
    "y = train_df[\"label\"]\n",
    "\n",
    "# Dividir en train y test (80% - 20%)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Modelo base\n",
    "base_model = CatBoostClassifier(\n",
    "    auto_class_weights='Balanced',\n",
    "    verbose=100,\n",
    "    random_state=42,\n",
    "    cat_features=cat_features,\n",
    "    text_features=text_features,\n",
    "    early_stopping_rounds = 100\n",
    ")\n",
    "\n",
    "# Hiperparámetros a explorar\n",
    "param_dist = {\n",
    "    'depth': [4, 6],\n",
    "    'learning_rate': np.linspace(0.01, 0.05, 5),\n",
    "    'iterations': [800, 1000],\n",
    "    'l2_leaf_reg': [5, 10, 20],\n",
    "    'min_data_in_leaf': [10, 20],\n",
    "    'bagging_temperature': [0.5, 1, 1.5],\n",
    "    'random_strength': [0.5, 1, 1.5]\n",
    "}\n",
    "\n",
    "stratified_cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Búsqueda aleatoria\n",
    "search = RandomizedSearchCV(\n",
    "    estimator=base_model,\n",
    "    param_distributions=param_dist,\n",
    "    n_iter=20,\n",
    "    scoring='f1_macro',\n",
    "    cv=stratified_cv,\n",
    "    verbose=3,\n",
    "    n_jobs=1\n",
    ")\n",
    "\n",
    "search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f27ee19-f006-4a1d-a081-1ea48908fc9a",
   "metadata": {},
   "source": [
    "train_pool = Pool(data=X_train, label=y_train, \n",
    "                  cat_features=cat_features, \n",
    "                  text_features=text_features)\n",
    "\n",
    "test_pool = Pool(data=X_test, label=y_test, \n",
    "                 cat_features=cat_features, \n",
    "                 text_features=text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64492fa-cd22-41fb-802c-f43664fdf622",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, classification_report# Entrenar\n",
    "model.fit(train_pool, eval_set=test_pool, use_best_model=True)\n",
    "\n",
    "best_model = search.best_estimator_\n",
    "\n",
    "# Predicción sobre el test set\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Evaluación\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "print(\"F1 macro:\", f1_score(y_test, y_pred, average=\"macro\"))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772e775f-5711-48d9-aa29-d50ed31eae51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from catboost import CatBoostClassifier, Pool\n",
    "\n",
    "# Obtener importancias\n",
    "importances = model.get_feature_importance()\n",
    "features = X_train.columns\n",
    "importance_df = pd.DataFrame({\"feature\": features, \"importance\": importances})\n",
    "importance_df = importance_df.sort_values(by=\"importance\", ascending=False).head(20)\n",
    "\n",
    "# Graficar\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df[\"feature\"][::-1], importance_df[\"importance\"][::-1])\n",
    "plt.xlabel(\"Feature Importance\")\n",
    "plt.title(\"Top 20 Feature Importances - CatBoost\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57b80275-0f0c-49cd-91b4-ce463e350568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subir a Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5890b11e-1ee0-420a-ad2d-33b9c1ed6acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"../../data/processed/test_preprocess_v1.csv\")\n",
    "df_test_id = test_df[\"id\"]\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50b1a1cb-9ed8-45d6-b47b-23fc0ed05ff4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"num_stopwords_tokens\"] = test_df[\"num_tokens\"] - test_df[\"num_tokens_without_stopwords\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8874d9b7-d43d-47fe-9bd4-dcd41e8466a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"pos_freq_without_stopwords_clean\"] = test_df[\"pos_freq_without_stopwords\"].apply(clean_counter)\n",
    "# Expandir en columnas\n",
    "pos_test_df_wo_stopwords = test_df[\"pos_freq_without_stopwords_clean\"].apply(pd.Series).fillna(0).astype(int)\n",
    "# Renombrar columnas\n",
    "pos_test_df_wo_stopwords.columns = [f\"pos_{col.upper()}\" for col in pos_test_df_wo_stopwords.columns]\n",
    "\n",
    "pos_test_df_wo_stopwords.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3070c22e-bb50-4104-845a-95b5ef81c52d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df, pos_test_df_wo_stopwords], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05b4005e-23e6-43e1-9c8b-732046f4687f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c9dc3a-cd54-4665-83de-70c51636e13f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar a ambas columnas\n",
    "test_df[\"tag_freq_without_stopwords\"] = test_df[\"tag_freq_without_stopwords\"].apply(clean_counter)\n",
    "\n",
    "# Expandir tags\n",
    "tag_df = test_df[\"tag_freq_without_stopwords\"].apply(pd.Series).fillna(0).astype(int)\n",
    "tag_df.columns = [f\"tag_count_{col}\" for col in tag_df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56301ba-bc8d-459a-914c-cc4efddaf307",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identificar columnas a eliminar\n",
    "tag_to_drop = [col for col in tag_df.columns if col not in tag_to_keep]\n",
    "\n",
    "# Crear 'tag_OTHER' como suma de las columnas poco frecuentes\n",
    "tag_df[\"tag_OTHER\"] = tag_df[tag_to_drop].sum(axis=1)\n",
    "\n",
    "# Eliminar columnas no deseadas\n",
    "tag_df = tag_df.drop(columns=tag_to_drop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc0a878-12dc-439a-8250-3a3cd28ce31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.concat([test_df, tag_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179f8203-ab51-4180-a2ea-9d6a1a0e092b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73285c1a-94f5-4a55-a0ee-c7ada766fb9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir strings tipo \"[tax, healthcare]\" en listas reales\n",
    "test_df[\"processed_subject\"] = test_df[\"processed_subject\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else []\n",
    ")\n",
    "\n",
    "# Aplanar la lista de subjects\n",
    "all_test_subjects = [item for sublist in test_df[\"processed_subject\"] for item in sublist]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db4e2d2-cb16-43d5-bd5b-37cbb4f1fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_subjects = [s if s in top_subjects else \"other\" for s in all_test_subjects]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0189040-3f4f-4a3b-a0bb-127a4f786467",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = list(set(filtered_subjects))\n",
    "print(len(unique_values))\n",
    "unique_values = list(set(all_test_subjects))\n",
    "print(len(unique_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4958fbe1-e468-4aa6-8e84-8cdf966d1740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inicializar a 0 las columnas dummies\n",
    "for subj in filtered_subjects:\n",
    "    test_df[f\"subject_{subj}\"] = 0\n",
    "\n",
    "test_df = test_df.apply(add_subject_dummies, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30c98ed8-8f09-4960-b76d-c90734a920bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e0f9a88-3358-4df6-90fd-39a61fbf7e37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformamos a lista\n",
    "test_df[\"speaker_job_tokens\"] = test_df[\"speaker_job_tokens\"].apply(ast.literal_eval)\n",
    "\n",
    "test_df[\"speaker_job_text\"] = test_df[\"speaker_job_tokens\"].apply(lambda x: \" \".join(x))\n",
    "test_df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096f1369-fc98-4968-87cc-713a455ad37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicar al DataFrame\n",
    "test_df[\"entity_list\"] = test_df[\"entities\"].apply(extract_entities)\n",
    "test_df[\"entity_list\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b97b95-0a19-4938-a4c6-2bc36414f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"entity_list\"] = test_df[\"entity_list\"].apply(lambda x: x if isinstance(x, list) else [])\n",
    "\n",
    "# Binarizar\n",
    "mlb = MultiLabelBinarizer()\n",
    "test_entity_dummies = pd.DataFrame(\n",
    "    mlb.fit_transform(test_df[\"entity_list\"]),\n",
    "    columns=[f\"entity_{cls}\" for cls in mlb.classes_],\n",
    "    index=test_df.index\n",
    ")\n",
    "\n",
    "test_entity_counts = test_entity_dummies.sum().sort_values(ascending=False)\n",
    "test_entity_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a61a0921-e7c6-4634-a1d9-a54b6f0dad08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nueva columna 'entity_OTHER' en entity_dummies\n",
    "test_drops = []\n",
    "test_keep = []\n",
    "for col in test_entity_dummies.columns.tolist():\n",
    "    if col in entities_to_keep:\n",
    "        test_keep.append(col)\n",
    "    else:\n",
    "        test_drops.append(col)\n",
    "        \n",
    "test_entity_dummies[\"entity_OTHER\"] = test_entity_dummies[test_drops].any(axis=1).astype(int)\n",
    "test_entity_dummies = test_entity_dummies.drop(columns=test_drops)\n",
    "test_entity_dummies.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80871936-7c13-476d-8d4a-02f4798592e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_entity_dummies.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c58b76-421c-4c0c-b47a-b8f8754e1f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[\"speaker_type\"] = test_df[\"speaker_type\"].apply(\n",
    "    lambda x: ast.literal_eval(x) if isinstance(x, str) else (x if isinstance(x, list) else [])\n",
    ")\n",
    "\n",
    "# Binarizar\n",
    "mlb = MultiLabelBinarizer()\n",
    "speaker_type_test_dummies = pd.DataFrame(\n",
    "    mlb.fit_transform(test_df[\"speaker_type\"]),\n",
    "    columns=[f\"speaker_type_{cls}\" for cls in mlb.classes_],\n",
    "    index=test_df.index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd44898-35e7-48f1-a058-d4714e3cfc1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdff5edf-3802-4309-ac43-6f85a398d8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c8141c-fb84-4197-a34c-efb32e881522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear nueva columna 'entity_OTHER' en entity_dummies\n",
    "test_speaker_drops = []\n",
    "test_speaker_keep = []\n",
    "for col in speaker_type_test_dummies.columns.tolist():\n",
    "    if col in speaker_to_keep:\n",
    "        test_speaker_keep.append(col)\n",
    "    else:\n",
    "        test_speaker_drops.append(col)\n",
    "        \n",
    "speaker_type_test_dummies[\"speaker_OTHER\"] = speaker_type_test_dummies[test_speaker_drops].any(axis=1).astype(int)\n",
    "speaker_type_test_dummies = speaker_type_test_dummies.drop(columns=test_speaker_drops)\n",
    "test_df = pd.concat([test_df,speaker_type_test_dummies],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3751e6e-e5a7-408b-b177-f7e89d04d7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_df = test_df.drop(columns=drop_cols)\n",
    "#test_df = test_df.drop(columns=[\"speaker\"])\n",
    "#test_df = test_df.drop(columns=[\"pos_freq_without_stopwords_clean\"])\n",
    "test_df = test_df[X.columns]\n",
    "X.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "020ecee4-e5ef-4a7c-9c3a-f30579094160",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1b0b64c-be17-4b97-8b01-e3dccf27f997",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pool = Pool(data=test_df,\n",
    "                 cat_features=cat_features, \n",
    "                 text_features=text_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23921393-66cb-4301-9c19-683b36399496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "y_pred_test = model.predict(test_pool)\n",
    "# Guardar predicciones\n",
    "current_date = datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "output = pd.DataFrame({\n",
    "    \"id\": df_test_id,\n",
    "    \"label\": y_pred_test.astype(int)\n",
    "})\n",
    "filename = f\"../3_summision/CatBoost_NewProcessing_{current_date}.csv\"\n",
    "output.to_csv(filename, index=False)\n",
    "print(f\"Predicciones guardadas en {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4039d9-9d47-449a-8e80-ad3ad8a32168",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81556cd9-de75-4903-901f-cc0a97bf7e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b2ab63-c7a9-4bd9-94ac-1547eae03944",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
